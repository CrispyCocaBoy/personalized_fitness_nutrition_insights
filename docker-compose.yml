services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper

  init_kafka_topic:
    build:
      context: .
      dockerfile: src/kafka/Dockerfile
    depends_on:
      - kafka
      - kafka-ui

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8085:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka


  mqtt_broker:
    image:  emqx/emqx-enterprise:5.6.0
    ports:
      - "1883:1883"       # MQTT
      - "8081:8081"       # HTTP API
      - "18083:18083"     # EMQX Dashboard
    volumes:
       - ./volumes/emqx_data/config/cluster.hocon:/opt/emqx/data/configs/
    container_name: mqtt_broker
    depends_on:
      - kafka

  minio:
    image: minio/minio
    ports:
      - "9000:9000"      # API
      - "9001:9001"      # Console
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./volumes/minio_setting:/data

  spark:
    image: bitnami/spark:latest
    environment:
      SPARK_MODE: master
    ports:
      - "8080:8080"
    depends_on:
      - kafka
      - minio
      - init_kafka_topic
      - kafka-ui

  spark-worker:
    image: bitnami/spark:latest
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark:7077
    depends_on:
      - spark


  fake_user:
    build:
      context: .
      dockerfile: ./src/consumer_data_generator/Dockerfile
    container_name: fake_user
    volumes:
      - ./database_utility/fake_user_and_password:/app/output
    depends_on:
      - postgres

  bpm_consumer:
      build:
        context: .
        dockerfile: src/delta/bronze/sensors_consumers/Dockerfile
      container_name: bpm_consumer
      depends_on:
        - kafka
        - spark
        - mqtt_broker

  query:
    build:
      context: .
      dockerfile: src/query/Dockerfile
    container_name: query
    depends_on:
      - kafka
      - spark
      - mqtt_broker

  streamlit_app:
    build:
      context: .
      dockerfile: ./src/frontend/Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - ./src/frontend:/app
      - ./utility:/app/utility

  bpm_producer:
    build:
      context: .                                  # la root del progetto
      dockerfile: src/sensors/bpm_producer/Dockerfile
    container_name: bpm_producer
    depends_on:
      - mqtt_broker
    networks:
      - default


  postgres:
    image: postgres:15
    container_name: user_device_db
    restart: always
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: user_device_db # contiene le demografiche
    ports:
      - "5432:5432"
    volumes:
      - ./volumes/ps_setting:/var/lib/postgresql/data

volumes:
  fake_generator_output: