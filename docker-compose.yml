services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper

  init_kafka_topic:
    build:
      context: .
      dockerfile: src/kafka/Dockerfile
    depends_on:
      - kafka
      - kafka-ui

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8085:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka

  spark:
    image: bitnami/spark:latest
    environment:
      SPARK_MODE: master
    ports:
      - "8080:8080"
    depends_on:
      - kafka
      - minio
      - init_kafka_topic
      - kafka-ui

  spark-worker:
    image: bitnami/spark:latest
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark:7077
    depends_on:
      - spark

  bpm_consumer:
      build:
        context: .
        dockerfile: src/delta/bronze/sensors_consumers/Dockerfile
      container_name: bpm_consumer
      depends_on:
        - kafka
        - spark
        - emqx1

  query:
    build:
      context: .
      dockerfile: src/query/Dockerfile
    container_name: query
    depends_on:
      - kafka
      - spark
      - emqx1

  streamlit_app:
    build:
      context: .
      dockerfile: ./src/frontend/Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - ./src/frontend:/app
      - ./utility:/app/utility

# Ingestion phase
  emqx1:
    image: emqx/emqx-enterprise:5.10.0
    container_name: emqx1
    environment:
      - "EMQX_NODE_NAME=emqx@node1.emqx.com"
      - "EMQX_CLUSTER__DISCOVERY_STRATEGY=static"
      - "EMQX_CLUSTER__STATIC__SEEDS=[emqx@node1.emqx.com,emqx@node2.emqx.com]"
    healthcheck:
      test: [ "CMD", "/opt/emqx/bin/emqx", "ctl", "status" ]
      interval: 5s
      timeout: 25s
      retries: 5
    networks:
      emqx-bridge:
        aliases:
          - node1.emqx.com
    ports:
      - 1883:1883     # MQTT
      - 8083:8083     # WebSocket
      - 8084:8084     # WSS
      - 8883:8883     # MQTT over TLS
      - 18083:18083   # Dashboard
    volumes:
      - ./emqx_data/config/cluster.hocon:/opt/emqx/data/configs/

## CI dovro ficcare un kafka che funziona


# Databases
  postgres:
    image: postgres:18beta1
    container_name: user_device_db
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: user_device_db
      PGDATA: /var/lib/postgresql/18/docker
    ports:
      - "5432:5432"
    volumes:
      - ./volumes/ps_setting:/var/lib/postgresql

  minio:
    image: minio/minio
    ports:
      - "9000:9000"      # API
      - "9001:9001"      # Console
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./volumes/minio_setting:/data

# Data Generator
  fake_user:
    build:
      context: .
      dockerfile: ./src/data_generator/producer_user_generator/Dockerfile
    container_name: fake_user
    volumes:
      - ./database_utility/fake_user_and_password:/app/output/
    depends_on:
      - postgres

  people_simulator:
    build:
      context: .                                  # la root del progetto
      dockerfile: src/data_generator/sensors/people_simulator/Dockerfile
    container_name: people_simulator
    networks:
      - emqx-bridge
    depends_on:
      - emqx1

volumes:
  fake_generator_output:

networks:
  emqx-bridge:
    driver: bridge